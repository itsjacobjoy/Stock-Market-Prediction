{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_stock = pd.read_csv(\"assets/TSLA.csv\")\n",
    "sc_shortage = pd.read_csv(\"assets/Semiconductor shortage affects.csv\")\n",
    "elon_tweets = pd.read_csv(\"assets/TweetsElonMusk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news = pd.read_csv('AAPL_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
       "       'user_id', 'username', 'name', 'place', 'tweet', 'language', 'mentions',\n",
       "       'urls', 'photos', 'replies_count', 'retweets_count', 'likes_count',\n",
       "       'hashtags', 'cashtags', 'link', 'retweet', 'quote_url', 'video',\n",
       "       'thumbnail', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
       "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
       "       'trans_dest'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elon_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_tweets = elon_tweets[elon_tweets['tweet'].str.contains('tesla', case=False)]\n",
    "\n",
    "new_dataframe = pd.DataFrame(tesla_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12     @tesla_adri @WholeMarsBlog These things are be...\n",
       "26     @AustinTeslaClub @OwenSparks_ @WholeMarsBlog G...\n",
       "28     @teslaownersSV @neuralink Turns out üêí love vid...\n",
       "38                                       @TeslaGong Yeah\n",
       "48     @IheartTesla Absolutely doable. Possibly as so...\n",
       "52     @IheartTesla @neuralink Hopefully, later this ...\n",
       "59     Thanks Tesla suppliers for providing us with c...\n",
       "76     @Teslarati @ResidentSponge Special mention of ...\n",
       "78     @Teslarati @ResidentSponge Great work by Tesla...\n",
       "100                             @teslaownersSV @Tesla ü§£ü§£\n",
       "112    @OwenSparks_ Agreed! We‚Äôre not super far, as M...\n",
       "136    @cleantechnica This is crazy. Should use Tesla...\n",
       "145    @WholeMarsBlog I think there is a &gt;0% chanc...\n",
       "163    Tesla is using only internal &amp; open source...\n",
       "164                 You can now buy a Tesla with Bitcoin\n",
       "187    @TeslaPhx @CodingMark @EvaFoxU @jrosinski97 @d...\n",
       "194                  @Teslarati –ü—Ä–µ—Å—Ç—É–ø–ª–µ–Ω—ñ–µ –∏ –Ω–∞–∫–∞–∑–∞–Ω—ñ–µ\n",
       "201                                     @teslaownersSV üíØ\n",
       "222    Play your favorite song in a Tesla &amp; turn ...\n",
       "247    @tesla_adri @28delayslater @TrevorMahlmann @Sp...\n",
       "270    @thesheetztweetz Not connecting Tesla cars to ...\n",
       "273    @Teslarati @KlenderJoey Still many fine detail...\n",
       "281    @LarryKellogg @arctechinc The Tesla FSD comput...\n",
       "282    Availability varies by region due to regulator...\n",
       "288    If you want the Tesla Full Self-Driving Beta d...\n",
       "296    @WholeMarsBlog Tesla AI, both hardware &amp; s...\n",
       "298    @skorusARK Tesla &amp; Ford are the only Ameri...\n",
       "308    @billhuang688 @F9Block5 @PPathole FSD beta bui...\n",
       "322                                   @teslaownersSV Yup\n",
       "330               @WholeMarsBlog Tesla China team rocks!\n",
       "348    @Rjdlandscapes @Tesla Prices in the US (of all...\n",
       "356    @teslaownersSV Probably mid year, but Starlink...\n",
       "362    @flcnhvy @HsueEugene @teslaownersSV @cleantech...\n",
       "363    @TesLatino @teslaownersSV @cleantechnica Many ...\n",
       "365    @HsueEugene @teslaownersSV @cleantechnica Seem...\n",
       "366    @teslaownersSV @cleantechnica We‚Äôre upgrading ...\n",
       "377    @jgrano305 @AustinTeslaClub We have too much p...\n",
       "379    @JantieWillie @Adamklotz_ @AustinTeslaClub Hop...\n",
       "380         @Adamklotz_ @AustinTeslaClub Later this year\n",
       "381    @jgrano305 @AustinTeslaClub It is still availa...\n",
       "382    @AustinTeslaClub The Tesla Solar Roof is sligh...\n",
       "383    @teslaownersSV Final design is lookingüëå Was ju...\n",
       "398    @WholeMarsBlog Most people have no idea, even ...\n",
       "410    @business To be clear, I am *not* an investor,...\n",
       "411    @business Tesla‚Äôs action is not directly refle...\n",
       "412    @Teslarati SpaceX in south Texas &amp; Tesla i...\n",
       "416    @Tesla Covered in snow &amp; ice, roads mostly...\n",
       "442    @teslacn Congratulations Tesla China for amazi...\n",
       "467     @CryptoShrikar @CoinDesk @Tesla @Dan_Z_Palmer ü§£ü§£\n",
       "469    @SRuhle Everyone at Tesla receives stock.   My...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataframe.tweet.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", tweet, flags=re.MULTILINE)\n",
    "    \n",
    "    tweet = re.sub(r'@\\w+|\\#\\w+', \"\", tweet)\n",
    "    \n",
    "    tweet = re.sub(r'[^\\w\\s]', \"\", tweet)\n",
    "    \n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/0l2nq7xx5yjbjdpkkfsnvb700000gn/T/ipykernel_67769/1356004391.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tesla_tweets['processed_tweet'] = tesla_tweets['tweet'].apply(preprocess_tweet)\n"
     ]
    }
   ],
   "source": [
    "tesla_tweets['processed_tweet'] = tesla_tweets['tweet'].apply(preprocess_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12         these things are best thought of as probabil...\n",
       "26          good point   next major software rev will d...\n",
       "28         turns out  love video games amp snacks just ...\n",
       "38                                                    yeah\n",
       "48        absolutely doable possibly as soon as neurali...\n",
       "                               ...                        \n",
       "12557        yeah not scalable my grad student idea was...\n",
       "12558       that was my night job day job was working o...\n",
       "12559       true ancient times  had to flip cpu registe...\n",
       "12560                                           absolutely\n",
       "12561      tesla is building up collision repair capabi...\n",
       "Name: processed_tweet, Length: 2378, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_tweets.processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "labels = ['Negative', 'Neutral', 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(tweet):\n",
    "    encoded_tweet = tokenizer(tweet, return_tensors='pt')\n",
    "    \n",
    "    output = model(**encoded_tweet)\n",
    "    \n",
    "    scores = output.logits.detach().numpy()[0]\n",
    "    scores = np.exp(scores) / np.exp(scores).sum()\n",
    "    \n",
    "    max_score_index = np.argmax(scores)\n",
    "    sentiment = labels[max_score_index]\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment2(tweet):\n",
    "    encoded_tweet = tokenizer(tweet, return_tensors='pt')\n",
    "    \n",
    "    output = model(**encoded_tweet)\n",
    "    \n",
    "    scores = output.logits.detach().numpy()[0]\n",
    "    scores = np.exp(scores) / np.exp(scores).sum()\n",
    "    \n",
    "    normalized_scores = scores - np.min(scores)\n",
    "    normalized_scores /= np.max(normalized_scores)\n",
    "    \n",
    "    return normalized_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/0l2nq7xx5yjbjdpkkfsnvb700000gn/T/ipykernel_67769/2810372690.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tesla_tweets['sentiment2'] = tesla_tweets['processed_tweet'].apply(analyze_sentiment2)\n"
     ]
    }
   ],
   "source": [
    "tesla_tweets['sentiment2'] = tesla_tweets['processed_tweet'].apply(analyze_sentiment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12        [0.0, 1.0, 0.8569846]\n",
       "26       [0.0, 0.22127925, 1.0]\n",
       "28       [0.0, 0.05958415, 1.0]\n",
       "38       [0.0, 1.0, 0.30451855]\n",
       "48       [0.0, 0.09361007, 1.0]\n",
       "                  ...          \n",
       "12557    [0.47573087, 1.0, 0.0]\n",
       "12558    [0.0, 1.0, 0.09367881]\n",
       "12559     [1.0, 0.7703952, 0.0]\n",
       "12560    [0.0, 0.90690523, 1.0]\n",
       "12561     [0.0, 0.5589807, 1.0]\n",
       "Name: sentiment2, Length: 2378, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_tweets.sentiment2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/0l2nq7xx5yjbjdpkkfsnvb700000gn/T/ipykernel_67769/1392690091.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tesla_tweets[labels] = pd.DataFrame(tesla_tweets['sentiment2'].tolist())\n",
      "/var/folders/yg/0l2nq7xx5yjbjdpkkfsnvb700000gn/T/ipykernel_67769/1392690091.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tesla_tweets[labels] = pd.DataFrame(tesla_tweets['sentiment2'].tolist())\n",
      "/var/folders/yg/0l2nq7xx5yjbjdpkkfsnvb700000gn/T/ipykernel_67769/1392690091.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tesla_tweets[labels] = pd.DataFrame(tesla_tweets['sentiment2'].tolist())\n"
     ]
    }
   ],
   "source": [
    "tesla_tweets[labels] = pd.DataFrame(tesla_tweets['sentiment2'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
       "       'user_id', 'username', 'name', 'place', 'tweet', 'language', 'mentions',\n",
       "       'urls', 'photos', 'replies_count', 'retweets_count', 'likes_count',\n",
       "       'hashtags', 'cashtags', 'link', 'retweet', 'quote_url', 'video',\n",
       "       'thumbnail', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
       "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
       "       'trans_dest', 'processed_tweet', 'sentiment2', 'Negative', 'Neutral',\n",
       "       'Positive'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date                    average_sentiment\n",
      "0   2011-12-31                [1.0, 0.7157263, 0.0]\n",
      "1   2012-01-11                [0.0, 1.0, 0.6601804]\n",
      "2   2012-01-13                [0.0, 0.4564618, 1.0]\n",
      "3   2012-01-17                [1.0, 0.6496006, 0.0]\n",
      "4   2012-01-18                [1.0, 0.4752943, 0.0]\n",
      "..         ...                                  ...\n",
      "931 2021-04-10         [0.0, 0.42695448, 0.9523282]\n",
      "932 2021-04-13                [0.0, 0.5589807, 1.0]\n",
      "933 2021-04-14  [0.32381523, 0.9354601, 0.21873577]\n",
      "934 2021-04-15  [0.25481036, 0.80302113, 0.2172761]\n",
      "935 2021-04-17              [0.0, 0.047333837, 1.0]\n",
      "\n",
      "[936 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/0l2nq7xx5yjbjdpkkfsnvb700000gn/T/ipykernel_67769/4151710855.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tesla_tweets['date'] = pd.to_datetime(tesla_tweets['date'], format='%Y-%m-%d')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tesla_tweets['date'] = pd.to_datetime(tesla_tweets['date'], format='%Y-%m-%d')\n",
    "\n",
    "unique_dates_sentiment = tesla_tweets.groupby('date')['sentiment2'].mean()\n",
    "\n",
    "new_dataframe = pd.DataFrame({'date': unique_dates_sentiment.index, 'average_sentiment': unique_dates_sentiment.values})\n",
    "\n",
    "new_dataframe = new_dataframe.sort_values(by='date')\n",
    "\n",
    "new_dataframe = new_dataframe.reset_index(drop=True)\n",
    "\n",
    "print(new_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final = new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_final[labels] = pd.DataFrame(tweets_final['average_sentiment'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_sentiment</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>[1.0, 0.7157263, 0.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715726</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-11</td>\n",
       "      <td>[0.0, 1.0, 0.6601804]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>[0.0, 0.4564618, 1.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456462</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-17</td>\n",
       "      <td>[1.0, 0.6496006, 0.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649601</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-18</td>\n",
       "      <td>[1.0, 0.4752943, 0.0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475294</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>2021-04-10</td>\n",
       "      <td>[0.0, 0.42695448, 0.9523282]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426954</td>\n",
       "      <td>0.952328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>2021-04-13</td>\n",
       "      <td>[0.0, 0.5589807, 1.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.558981</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>2021-04-14</td>\n",
       "      <td>[0.32381523, 0.9354601, 0.21873577]</td>\n",
       "      <td>0.323815</td>\n",
       "      <td>0.935460</td>\n",
       "      <td>0.218736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>2021-04-15</td>\n",
       "      <td>[0.25481036, 0.80302113, 0.2172761]</td>\n",
       "      <td>0.254810</td>\n",
       "      <td>0.803021</td>\n",
       "      <td>0.217276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>2021-04-17</td>\n",
       "      <td>[0.0, 0.047333837, 1.0]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047334</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>936 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                    average_sentiment  Negative   Neutral   \n",
       "0   2011-12-31                [1.0, 0.7157263, 0.0]  1.000000  0.715726  \\\n",
       "1   2012-01-11                [0.0, 1.0, 0.6601804]  0.000000  1.000000   \n",
       "2   2012-01-13                [0.0, 0.4564618, 1.0]  0.000000  0.456462   \n",
       "3   2012-01-17                [1.0, 0.6496006, 0.0]  1.000000  0.649601   \n",
       "4   2012-01-18                [1.0, 0.4752943, 0.0]  1.000000  0.475294   \n",
       "..         ...                                  ...       ...       ...   \n",
       "931 2021-04-10         [0.0, 0.42695448, 0.9523282]  0.000000  0.426954   \n",
       "932 2021-04-13                [0.0, 0.5589807, 1.0]  0.000000  0.558981   \n",
       "933 2021-04-14  [0.32381523, 0.9354601, 0.21873577]  0.323815  0.935460   \n",
       "934 2021-04-15  [0.25481036, 0.80302113, 0.2172761]  0.254810  0.803021   \n",
       "935 2021-04-17              [0.0, 0.047333837, 1.0]  0.000000  0.047334   \n",
       "\n",
       "     Positive  \n",
       "0    0.000000  \n",
       "1    0.660180  \n",
       "2    1.000000  \n",
       "3    0.000000  \n",
       "4    0.000000  \n",
       "..        ...  \n",
       "931  0.952328  \n",
       "932  1.000000  \n",
       "933  0.218736  \n",
       "934  0.217276  \n",
       "935  1.000000  \n",
       "\n",
       "[936 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-11-08</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.602000</td>\n",
       "      <td>1.665333</td>\n",
       "      <td>1.665333</td>\n",
       "      <td>7642500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-11-09</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.712667</td>\n",
       "      <td>1.603333</td>\n",
       "      <td>1.642000</td>\n",
       "      <td>1.642000</td>\n",
       "      <td>14346000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-11-10</td>\n",
       "      <td>1.632000</td>\n",
       "      <td>1.998000</td>\n",
       "      <td>1.603333</td>\n",
       "      <td>1.957333</td>\n",
       "      <td>1.957333</td>\n",
       "      <td>45907500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-11-11</td>\n",
       "      <td>1.906667</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>1.822000</td>\n",
       "      <td>1.869333</td>\n",
       "      <td>1.869333</td>\n",
       "      <td>29179500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-11-12</td>\n",
       "      <td>1.883333</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>1.871333</td>\n",
       "      <td>1.989333</td>\n",
       "      <td>1.989333</td>\n",
       "      <td>40936500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>163.169998</td>\n",
       "      <td>163.279999</td>\n",
       "      <td>158.830002</td>\n",
       "      <td>161.830002</td>\n",
       "      <td>161.830002</td>\n",
       "      <td>109015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>2023-05-02</td>\n",
       "      <td>161.880005</td>\n",
       "      <td>165.490005</td>\n",
       "      <td>158.929993</td>\n",
       "      <td>160.309998</td>\n",
       "      <td>160.309998</td>\n",
       "      <td>128259700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>160.009995</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>159.910004</td>\n",
       "      <td>160.610001</td>\n",
       "      <td>160.610001</td>\n",
       "      <td>119728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>162.710007</td>\n",
       "      <td>162.949997</td>\n",
       "      <td>159.649994</td>\n",
       "      <td>161.199997</td>\n",
       "      <td>161.199997</td>\n",
       "      <td>95108500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>163.970001</td>\n",
       "      <td>170.789993</td>\n",
       "      <td>163.509995</td>\n",
       "      <td>170.059998</td>\n",
       "      <td>170.059998</td>\n",
       "      <td>107440900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3144 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close   \n",
       "0     2010-11-08    1.633333    1.666667    1.602000    1.665333    1.665333  \\\n",
       "1     2010-11-09    1.666667    1.712667    1.603333    1.642000    1.642000   \n",
       "2     2010-11-10    1.632000    1.998000    1.603333    1.957333    1.957333   \n",
       "3     2010-11-11    1.906667    1.940000    1.822000    1.869333    1.869333   \n",
       "4     2010-11-12    1.883333    2.033333    1.871333    1.989333    1.989333   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "3139  2023-05-01  163.169998  163.279999  158.830002  161.830002  161.830002   \n",
       "3140  2023-05-02  161.880005  165.490005  158.929993  160.309998  160.309998   \n",
       "3141  2023-05-03  160.009995  165.000000  159.910004  160.610001  160.610001   \n",
       "3142  2023-05-04  162.710007  162.949997  159.649994  161.199997  161.199997   \n",
       "3143  2023-05-05  163.970001  170.789993  163.509995  170.059998  170.059998   \n",
       "\n",
       "         Volume  \n",
       "0       7642500  \n",
       "1      14346000  \n",
       "2      45907500  \n",
       "3      29179500  \n",
       "4      40936500  \n",
       "...         ...  \n",
       "3139  109015000  \n",
       "3140  128259700  \n",
       "3141  119728000  \n",
       "3142   95108500  \n",
       "3143  107440900  \n",
       "\n",
       "[3144 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date        Open        High         Low       Close   Adj Close   \n",
      "0     2010-11-11    1.633333    1.666667    1.602000    1.665333    1.665333  \\\n",
      "1     2010-11-12    1.666667    1.712667    1.603333    1.642000    1.642000   \n",
      "2     2010-11-13    1.632000    1.998000    1.603333    1.957333    1.957333   \n",
      "3     2010-11-14    1.906667    1.940000    1.822000    1.869333    1.869333   \n",
      "4     2010-11-15    1.883333    2.033333    1.871333    1.989333    1.989333   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "3139  2023-05-04  163.169998  163.279999  158.830002  161.830002  161.830002   \n",
      "3140  2023-05-05  161.880005  165.490005  158.929993  160.309998  160.309998   \n",
      "3141  2023-05-06  160.009995  165.000000  159.910004  160.610001  160.610001   \n",
      "3142  2023-05-07  162.710007  162.949997  159.649994  161.199997  161.199997   \n",
      "3143  2023-05-08  163.970001  170.789993  163.509995  170.059998  170.059998   \n",
      "\n",
      "         Volume  \n",
      "0       7642500  \n",
      "1      14346000  \n",
      "2      45907500  \n",
      "3      29179500  \n",
      "4      40936500  \n",
      "...         ...  \n",
      "3139  109015000  \n",
      "3140  128259700  \n",
      "3141  119728000  \n",
      "3142   95108500  \n",
      "3143  107440900  \n",
      "\n",
      "[3144 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tesla_stock['Date'] = pd.to_datetime(tesla_stock['Date'])\n",
    "\n",
    "tesla_stock['Date'] += pd.DateOffset(days=3)\n",
    "\n",
    "tesla_stock['Date'] = tesla_stock['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "print(tesla_stock)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date                    average_sentiment  Negative   Neutral   \n",
      "0   2011-12-31                [1.0, 0.7157263, 0.0]  1.000000  0.715726  \\\n",
      "1   2012-01-13                [0.0, 0.4564618, 1.0]  0.000000  0.456462   \n",
      "2   2012-02-10  [0.33333334, 0.67837197, 0.3486577]  0.333333  0.678372   \n",
      "3   2012-04-06               [0.0, 0.63404477, 1.0]  0.000000  0.634045   \n",
      "4   2012-05-10               [0.12222295, 1.0, 0.0]  0.122223  1.000000   \n",
      "..         ...                                  ...       ...       ...   \n",
      "630 2021-04-08               [0.0, 0.13217683, 1.0]  0.000000  0.132177   \n",
      "631 2021-04-09         [0.0, 0.57106835, 0.7681729]  0.000000  0.571068   \n",
      "632 2021-04-10         [0.0, 0.42695448, 0.9523282]  0.000000  0.426954   \n",
      "633 2021-04-15  [0.25481036, 0.80302113, 0.2172761]  0.254810  0.803021   \n",
      "634 2021-04-17              [0.0, 0.047333837, 1.0]  0.000000  0.047334   \n",
      "\n",
      "     Positive       Date        Open        High         Low       Close   \n",
      "0    0.000000 2011-12-31    1.932667    1.949333    1.869333    1.900667  \\\n",
      "1    1.000000 2012-01-13    1.829333    1.850667    1.816667    1.841333   \n",
      "2    0.348658 2012-02-10    2.120000    2.120000    2.054667    2.106667   \n",
      "3    1.000000 2012-04-06    2.446667    2.564667    2.444667    2.534000   \n",
      "4    0.000000 2012-05-10    2.130667    2.172000    2.107333    2.164667   \n",
      "..        ...        ...         ...         ...         ...         ...   \n",
      "630  1.000000 2021-04-08  235.903336  236.053329  228.233337  230.350006   \n",
      "631  0.768173 2021-04-09  230.100006  232.183334  227.123337  230.539993   \n",
      "632  0.952328 2021-04-10  229.000000  230.460007  222.613327  223.656662   \n",
      "633  0.217276 2021-04-15  228.566666  234.933334  227.363327  233.993332   \n",
      "634  1.000000 2021-04-17  256.899994  260.263336  242.676666  244.076660   \n",
      "\n",
      "      Adj Close     Volume  \n",
      "0      1.900667    8628000  \n",
      "1      1.841333   10077000  \n",
      "2      2.106667   15324000  \n",
      "3      2.534000   16471500  \n",
      "4      2.164667   17370000  \n",
      "..          ...        ...  \n",
      "630  230.350006  125528400  \n",
      "631  230.539993   84815400  \n",
      "632  223.656662   78928200  \n",
      "633  233.993332   87407100  \n",
      "634  244.076660  147052200  \n",
      "\n",
      "[635 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tweets_final['date'] = pd.to_datetime(tweets_final['date'], format='%Y-%m-%d')\n",
    "tesla_stock['Date'] = pd.to_datetime(tesla_stock['Date'], format='%Y-%m-%d')\n",
    "\n",
    "merged_data = pd.merge(tweets_final, tesla_stock, left_on='date', right_on='Date', how='inner')\n",
    "\n",
    "print(merged_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_tweets = merged_data.drop(columns = [\"Date\", \"average_sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>average_sentiment</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>1.932667</td>\n",
       "      <td>1.949333</td>\n",
       "      <td>1.869333</td>\n",
       "      <td>1.900667</td>\n",
       "      <td>1.900667</td>\n",
       "      <td>8628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>1.829333</td>\n",
       "      <td>1.850667</td>\n",
       "      <td>1.816667</td>\n",
       "      <td>1.841333</td>\n",
       "      <td>1.841333</td>\n",
       "      <td>10077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-02-10</td>\n",
       "      <td>0.015324</td>\n",
       "      <td>2012-02-10</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.054667</td>\n",
       "      <td>2.106667</td>\n",
       "      <td>2.106667</td>\n",
       "      <td>15324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2012-04-06</td>\n",
       "      <td>2.446667</td>\n",
       "      <td>2.564667</td>\n",
       "      <td>2.444667</td>\n",
       "      <td>2.534000</td>\n",
       "      <td>2.534000</td>\n",
       "      <td>16471500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-05-10</td>\n",
       "      <td>-0.122223</td>\n",
       "      <td>2012-05-10</td>\n",
       "      <td>2.130667</td>\n",
       "      <td>2.172000</td>\n",
       "      <td>2.107333</td>\n",
       "      <td>2.164667</td>\n",
       "      <td>2.164667</td>\n",
       "      <td>17370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>235.903336</td>\n",
       "      <td>236.053329</td>\n",
       "      <td>228.233337</td>\n",
       "      <td>230.350006</td>\n",
       "      <td>230.350006</td>\n",
       "      <td>125528400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>0.768173</td>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>230.100006</td>\n",
       "      <td>232.183334</td>\n",
       "      <td>227.123337</td>\n",
       "      <td>230.539993</td>\n",
       "      <td>230.539993</td>\n",
       "      <td>84815400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>2021-04-10</td>\n",
       "      <td>0.952328</td>\n",
       "      <td>2021-04-10</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>230.460007</td>\n",
       "      <td>222.613327</td>\n",
       "      <td>223.656662</td>\n",
       "      <td>223.656662</td>\n",
       "      <td>78928200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>2021-04-15</td>\n",
       "      <td>-0.037534</td>\n",
       "      <td>2021-04-15</td>\n",
       "      <td>228.566666</td>\n",
       "      <td>234.933334</td>\n",
       "      <td>227.363327</td>\n",
       "      <td>233.993332</td>\n",
       "      <td>233.993332</td>\n",
       "      <td>87407100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>2021-04-17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2021-04-17</td>\n",
       "      <td>256.899994</td>\n",
       "      <td>260.263336</td>\n",
       "      <td>242.676666</td>\n",
       "      <td>244.076660</td>\n",
       "      <td>244.076660</td>\n",
       "      <td>147052200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>635 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  average_sentiment       Date        Open        High   \n",
       "0   2011-12-31          -1.000000 2011-12-31    1.932667    1.949333  \\\n",
       "1   2012-01-13           1.000000 2012-01-13    1.829333    1.850667   \n",
       "2   2012-02-10           0.015324 2012-02-10    2.120000    2.120000   \n",
       "3   2012-04-06           1.000000 2012-04-06    2.446667    2.564667   \n",
       "4   2012-05-10          -0.122223 2012-05-10    2.130667    2.172000   \n",
       "..         ...                ...        ...         ...         ...   \n",
       "630 2021-04-08           1.000000 2021-04-08  235.903336  236.053329   \n",
       "631 2021-04-09           0.768173 2021-04-09  230.100006  232.183334   \n",
       "632 2021-04-10           0.952328 2021-04-10  229.000000  230.460007   \n",
       "633 2021-04-15          -0.037534 2021-04-15  228.566666  234.933334   \n",
       "634 2021-04-17           1.000000 2021-04-17  256.899994  260.263336   \n",
       "\n",
       "            Low       Close   Adj Close     Volume  \n",
       "0      1.869333    1.900667    1.900667    8628000  \n",
       "1      1.816667    1.841333    1.841333   10077000  \n",
       "2      2.054667    2.106667    2.106667   15324000  \n",
       "3      2.444667    2.534000    2.534000   16471500  \n",
       "4      2.107333    2.164667    2.164667   17370000  \n",
       "..          ...         ...         ...        ...  \n",
       "630  228.233337  230.350006  230.350006  125528400  \n",
       "631  227.123337  230.539993  230.539993   84815400  \n",
       "632  222.613327  223.656662  223.656662   78928200  \n",
       "633  227.363327  233.993332  233.993332   87407100  \n",
       "634  242.676666  244.076660  244.076660  147052200  \n",
       "\n",
       "[635 rows x 9 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_tweets.to_csv(\"tesla_sentiment.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# added prediction based on elon tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_deaths = pd.read_csv(\"assets/Tesla Deaths - Sudden Acceleration.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.unique of 0        22-January-15\n",
       "1         2-October-19\n",
       "2      29-September-19\n",
       "3      24-September-19\n",
       "4        18-October-19\n",
       "            ...       \n",
       "117          29-Nov-17\n",
       "118          24-Feb-16\n",
       "119           4-Aug-15\n",
       "120          21-Sep-13\n",
       "121          29-Jul-13\n",
       "Name: Incident Date, Length: 122, dtype: object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_deaths['Incident Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2011-12-31\n",
       "1     2012-01-13\n",
       "2     2012-02-10\n",
       "3     2012-04-06\n",
       "4     2012-05-10\n",
       "         ...    \n",
       "630   2021-04-08\n",
       "631   2021-04-09\n",
       "632   2021-04-10\n",
       "633   2021-04-15\n",
       "634   2021-04-17\n",
       "Name: date, Length: 635, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_tweets.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_dates = pd.to_datetime(tesla_deaths['Incident Date'], format='%d-%B-%y').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Print the converted dates\n",
    "print(converted_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_mapping = {\n",
    "    'January': '01', 'Jan': '01', 'Jan.': '01',\n",
    "    'February': '02', 'Feb': '02', 'Feb.': '02',\n",
    "    'March': '03', 'Mar': '03', 'Mar.': '03',\n",
    "    'April': '04', 'Apr': '04', 'Apr.': '04',\n",
    "    'May': '05',\n",
    "    'June': '06', 'Jun': '06', 'Jun.': '06',\n",
    "    'July': '07', 'Jul': '07', 'Jul.': '07',\n",
    "    'August': '08', 'Aug': '08', 'Aug.': '08',\n",
    "    'September': '09', 'Sept': '09', 'Sept.': '09','Sep': '09',\n",
    "    'October': '10', 'Oct': '10', 'Oct.': '10', '10ober':'10',\n",
    "    'November': '11', 'Nov': '11', 'Nov.': '11',\n",
    "    'December': '12', 'Dec': '12', 'Dec.': '12'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_deaths['Incident Date'] = tesla_deaths['Incident Date'].replace(month_mapping, regex=True).apply(pd.to_datetime, format='%d-%m-%y').dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2015-01-22\n",
       "1      2019-10-02\n",
       "2      2019-09-29\n",
       "3      2019-09-24\n",
       "4      2019-10-18\n",
       "          ...    \n",
       "117    2017-11-29\n",
       "118    2016-02-24\n",
       "119    2015-08-04\n",
       "120    2013-09-21\n",
       "121    2013-07-29\n",
       "Name: Incident Date, Length: 122, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla_deaths['Incident Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.715726</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.932667</td>\n",
       "      <td>1.949333</td>\n",
       "      <td>1.869333</td>\n",
       "      <td>1.900667</td>\n",
       "      <td>1.900667</td>\n",
       "      <td>8628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.829333</td>\n",
       "      <td>1.850667</td>\n",
       "      <td>1.816667</td>\n",
       "      <td>1.841333</td>\n",
       "      <td>1.841333</td>\n",
       "      <td>10077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-02-10</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.678372</td>\n",
       "      <td>0.348658</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.120000</td>\n",
       "      <td>2.054667</td>\n",
       "      <td>2.106667</td>\n",
       "      <td>2.106667</td>\n",
       "      <td>15324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.634045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.446667</td>\n",
       "      <td>2.564667</td>\n",
       "      <td>2.444667</td>\n",
       "      <td>2.534000</td>\n",
       "      <td>2.534000</td>\n",
       "      <td>16471500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-05-10</td>\n",
       "      <td>0.122223</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.130667</td>\n",
       "      <td>2.172000</td>\n",
       "      <td>2.107333</td>\n",
       "      <td>2.164667</td>\n",
       "      <td>2.164667</td>\n",
       "      <td>17370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>235.903336</td>\n",
       "      <td>236.053329</td>\n",
       "      <td>228.233337</td>\n",
       "      <td>230.350006</td>\n",
       "      <td>230.350006</td>\n",
       "      <td>125528400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>2021-04-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571068</td>\n",
       "      <td>0.768173</td>\n",
       "      <td>230.100006</td>\n",
       "      <td>232.183334</td>\n",
       "      <td>227.123337</td>\n",
       "      <td>230.539993</td>\n",
       "      <td>230.539993</td>\n",
       "      <td>84815400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>2021-04-10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426954</td>\n",
       "      <td>0.952328</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>230.460007</td>\n",
       "      <td>222.613327</td>\n",
       "      <td>223.656662</td>\n",
       "      <td>223.656662</td>\n",
       "      <td>78928200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>2021-04-15</td>\n",
       "      <td>0.254810</td>\n",
       "      <td>0.803021</td>\n",
       "      <td>0.217276</td>\n",
       "      <td>228.566666</td>\n",
       "      <td>234.933334</td>\n",
       "      <td>227.363327</td>\n",
       "      <td>233.993332</td>\n",
       "      <td>233.993332</td>\n",
       "      <td>87407100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>2021-04-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>256.899994</td>\n",
       "      <td>260.263336</td>\n",
       "      <td>242.676666</td>\n",
       "      <td>244.076660</td>\n",
       "      <td>244.076660</td>\n",
       "      <td>147052200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>635 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  Negative   Neutral  Positive        Open        High   \n",
       "0   2011-12-31  1.000000  0.715726  0.000000    1.932667    1.949333  \\\n",
       "1   2012-01-13  0.000000  0.456462  1.000000    1.829333    1.850667   \n",
       "2   2012-02-10  0.333333  0.678372  0.348658    2.120000    2.120000   \n",
       "3   2012-04-06  0.000000  0.634045  1.000000    2.446667    2.564667   \n",
       "4   2012-05-10  0.122223  1.000000  0.000000    2.130667    2.172000   \n",
       "..         ...       ...       ...       ...         ...         ...   \n",
       "630 2021-04-08  0.000000  0.132177  1.000000  235.903336  236.053329   \n",
       "631 2021-04-09  0.000000  0.571068  0.768173  230.100006  232.183334   \n",
       "632 2021-04-10  0.000000  0.426954  0.952328  229.000000  230.460007   \n",
       "633 2021-04-15  0.254810  0.803021  0.217276  228.566666  234.933334   \n",
       "634 2021-04-17  0.000000  0.047334  1.000000  256.899994  260.263336   \n",
       "\n",
       "            Low       Close   Adj Close     Volume  \n",
       "0      1.869333    1.900667    1.900667    8628000  \n",
       "1      1.816667    1.841333    1.841333   10077000  \n",
       "2      2.054667    2.106667    2.106667   15324000  \n",
       "3      2.444667    2.534000    2.534000   16471500  \n",
       "4      2.107333    2.164667    2.164667   17370000  \n",
       "..          ...         ...         ...        ...  \n",
       "630  228.233337  230.350006  230.350006  125528400  \n",
       "631  227.123337  230.539993  230.539993   84815400  \n",
       "632  222.613327  223.656662  223.656662   78928200  \n",
       "633  227.363327  233.993332  233.993332   87407100  \n",
       "634  242.676666  244.076660  244.076660  147052200  \n",
       "\n",
       "[635 rows x 10 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
